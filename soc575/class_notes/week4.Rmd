---
title: "Week 4"
output: html_document
---

```{r, warning = F, message = F}
library(here)
library(dplyr)
library(purrr)
library(haven)
library(ggplot2)
library(forcats)
library(reghelper)
library(sjlabelled)
```

```{r}
data <- haven::read_dta(here("class data.dta"))
noMissing <-
    data %>%
    select(f2evdost, bypared, by2xrirr, bys43) %>%
    filter(across(everything(), ~!is.na(.x)))
```

There's a lot you can do with the smoking variable. You can treat them as dummy variables. You can re-code it to be binary. It may not make the most sense to be treating it as a continuous, numeric variable.

```{r}
model <- lm(f2evdost ~ bypared + by2xrirr + bys43, data = noMissing)
summary(model)

newData <-
    tibble(bys43 = unique(noMissing$bys43),
           bypared = rep(mean(noMissing$bypared), length(unique(noMissing$bys43))),
           by2xrirr = rep(mean(noMissing$by2xrirr), length(unique(noMissing$bys43))))

predict <-
    predict(model,
            newdata = newData,
            se.fit = T,
            interval = "confidence",
            level = 0.95)

graphPredictions <-
    newData %>%
    bind_cols(as_tibble(predict$fit))

ggplot(noMissing, aes(x = bys43, y = f2evdost)) +
    geom_point(data = graphPredictions, aes(x = bys43, y = fit)) +
    geom_errorbar(data = graphPredictions,
                  aes(x = bys43, ymin = lwr, ymax = upr),
                  inherit.aes = F) +
    #geom_line(aes(x = bys43, y = fit), data = graphPredictions, inherit.aes = F) + 
    geom_smooth(data = graphPredictions,
                aes(x = bys43, y = fit),
                method = "lm",
                se = F,
                formula = y ~ x,
                inherit.aes = F) +
    scale_x_continuous(label = c("i don^t smoke",
                               "1-5 cigarettes",
                               "about 1/2 pack",
                               "mt 1/2,lt 2 packs",
                               "2 packs or more"),
                       breaks = c(0, 1, 2, 3, 4)) +
    theme_bw()
```

## Logistic Regression

```{r}
logitModel <- glm(f2evdost ~ by2xrirr + bypared + bygrads + byfaminc + bys55f +
                      bys45 + bys53,
                  data = data,
                  family = "binomial")
summary(logitModel)

# Odds Ratios, for a unit increase in reading test scores, the odds of dropout
# are expected to decrease by a factor of 0.975 holding all other variables
# constant.

# For a unit increase in reading test scores, the odds of dropout decrease by
# 2.5% holding all other variables constant.
exp(coef(logitModel))

# Standardize the independent variables
# For a std. dev. increase in reading test scores, the odds of dropout
# decrease by about 20%.
exp(coef(beta(logitModel, y = F)))

noMissingLogit <-
    data %>%
    select(f2evdost, by2xrirr, bypared, bygrads, byfaminc, bys55f, bys45, bys53) %>%
    filter(across(everything(), ~!is.na(.x)))

# standard deviations
map(noMissingLogit, sd)
```

