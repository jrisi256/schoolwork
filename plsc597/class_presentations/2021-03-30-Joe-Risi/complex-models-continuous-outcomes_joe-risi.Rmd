---
title: "2021 March 30 - Joseph Risi - Complex Models for Continuous Outcomes"
output: html_document
---

* http://ippsr.msu.edu/public-policy/correlates-state-policy - Link to the **Correlates of State Public Policy** website. The aim of the project is to be a *one-stop shop* for researchers looking to track policy changes and state-level variables over time. The dataset is quite extensive as it has thousands of variables for each state (in some cases going back as far as 1900).
* https://ippsr.msu.edu/sites/default/files/CorrelatesCodebook.pdf - Link to the variable codebook which contains somewhat detailed information on every variable in the dataset.
* https://github.com/correlatesstatepolicy/cspp - Link to the Github repository for the R package allowing for access to the dataset.
* https://cspp.ippsr.msu.edu/cspp/#tab-9832-5 - Link to a Shiny app the researchers built allowing for interactive exploration and search of the dataset.

The goal of this presentation will be to build a model which can predict infant mortality. While infant health is not my area of expertise or research, I picked variables I thought were either interesting or somehow related to infant mortality.

**The Variables**

* **Dependent Variable**: Infant Mortality Rate which is measured as the number of infant deaths per 1000 live birth. This measure is available for every state from 1995 - 2005 and then from 2014 - 2017.
* **Independent Variables**: For some of these variables, it's unclear to me exactly how the rate is being calculated. If I were to pursue this reseach project further, I would do more research into how these rates are being generated.
    * **vcrimerate**: Violent crime rate
    * **propcrimerate**: Property crime rate
    * **z_cigarette_taxes**: Cigarette tax rate
    * **cbeertex**: Beer excise tax rates (dollars per gallon, off-premises sales). This was the only alcohol-related tax I could find which was available in roughly the same years as our dependent variable.
    * **statemin**: The state minimum wage.
    * **unemployment**: The unemployment rate.
    * **povrate**: The poverty rate.
    * **cons_fossil**: I scale (subtract the mean, divide by standard deviation) **cons_fossil** (fossil fuel consumption in billion BTU) within each year to make cross-year and cross-state comparisons more meaningful. 
    * **ranney1_sen_dem_prop**: Proportion of state senate members who are Democrats.
    * **ranney2_hs_dem_prop**: Proportion of state house members who are Democrats.

```{r, warning = F, message = F}
library(mlr)
library(cspp)
library(kknn)
library(purrr)
library(dplyr)
library(tidyr)
library(xgboost)
library(ggplot2)
library(parallel)
library(ggcorrplot)
library(parallelMap)
```

## Clean the data

Aside from scaling the fossil fuel consumption variable, I filter out the District of Columbia and Nebraska due to extensive missingness of data.

```{r}
vars <- c("infantmortality", "vcrimerate", "propcrimerate", "z_cigarette_taxes",
          "cbeertex", "statemin", "unemployment", "povrate", "cons_fossil",
          "ranney1_sen_dem_prop", "ranney2_hs_dem_prop")

data <-
    get_cspp_data(vars = vars) %>%
    filter(!is.na(infantmortality), !state %in% c("District of Columbia", "Nebraska")) %>%
    select(-st.abb, -stateno, -state_fips, -state_icpsr) %>%
    mutate(across(-state, as.numeric)) %>%
    group_by(year) %>%
    mutate(scaled_fossil = (cons_fossil - mean(cons_fossil)) / sd(cons_fossil),
           state = as.factor(state)) %>%
    ungroup() %>%
    select(-cons_fossil)
```

## Data Exploration

How much data are we missing? Some of our variables have a moderate amount of missingess which we will have to deal with later.

```{r}
map(data, ~sum(is.na(.x)))
```

Let's get a sense of the linear relationship between each independent variable and the dependent variable.

```{r}
dataUntidy <- data %>% pivot_longer(c(-infantmortality, -state))
ggplot(dataUntidy, aes(value, infantmortality)) +
    facet_wrap(~ name, scale = "free_x") +
    geom_point() +
    geom_smooth(method = "lm") +
    theme_bw()
```

Let's see a correlation matrix between all of our variables (since they are all numeric).

```{r}
corrMatrix <- cor(select(data, -year, -state), use = "complete.obs")

ggcorrplot(corrMatrix,
           type = "lower",
           method = "circle",
           colors = c("red", "white", "blue"))
```

## Split data into test and train

```{r}
set.seed(420)
train <- data %>% sample_frac(0.70)
test <- anti_join(data, train)
```

## Impute Missing Data for train and reimpute the data for test

We are going to use a decision tree to impute missing values. Normally we wouldn't have to worry about missing values since random forest and xgboost can handle missing values. K-nearest neighbors cannot handle missing values though.

We are also going to use the model learned on our train set to also impute the missing values in our test set.

```{r}
imputeMethod <- imputeLearner("regr.rpart")
trainImputed <- impute(as.data.frame(train),
                       classes = list(numeric = imputeMethod))
testImputed <- reimpute(test, trainImputed$desc)
```

## Create our task and our learners

You may have noticed above I don't include year or state in my independent variables. I do include them in the imputation model because they're undoubtedly useful for imputing missing values. However I don't wish to include them in the prediction models. For this exercise, I want to see how much the characteristics of states (rather than the states themselves) can predict the infant mortality rates. I also want to see if our results can generalize across time.

```{r}
# Create the training task on the imputed data not including year or state
infantMortalityTaskTrain <-
    makeRegrTask(data = select(trainImputed$data, -year, -state),
                 target = "infantmortality")

# Create our learners
knn <- makeLearner("regr.kknn")
forest <- makeLearner("regr.randomForest")
xgb <- makeLearner("regr.xgboost")

# We will be using 10-fold cross-validation for hyperparameter tuning
kFold10 <- makeResampleDesc("CV", iters = 10)

# For kNN, we will search across the entire parameter space
gridSearch <- makeTuneControlGrid()

# Tree-based algos will explore 500 different combinations of hyperparameters
randSearch <- makeTuneControlRandom(maxit = 500)
```

## Tune the hyperparameters for kNN

k-nearest neighbors only has one parameter to tune (k or the number of neighbords to consider).

```{r}
knnParamSpace <- makeParamSet(makeDiscreteParam("k", values = 1:50))

tunedKnn <- tuneParams(knn,
                       task = infantMortalityTaskTrain,
                       resampling = kFold10,
                       par.set = knnParamSpace,
                       control = gridSearch)

tunedKnn
```

Did we find a local or global minimum for our hyperparameter?

```{r}
knnTuningData <- generateHyperParsEffectData(tunedKnn)

plotHyperParsEffect(knnTuningData, x = "k",
                    y = "mse.test.mean",
                    plot.type = "line") +
    theme_bw()
```

## Tune the hyperparameters for random forest

```{r}
forestParamSpace <-
    makeParamSet(makeIntegerParam("ntree", lower = 200, upper = 200),
                 makeIntegerParam("mtry", lower = 5, upper = 10),
                 makeIntegerParam("nodesize", lower = 1, upper = 10),
                 makeIntegerParam("maxnodes", lower = 5, upper = 30))

parallelStartSocket(cpus = detectCores())

tunedRandomForest <- tuneParams(forest,
                                task = infantMortalityTaskTrain,
                                resampling = kFold10,
                                par.set = forestParamSpace,
                                control = randSearch)

parallelStop()

tunedRandomForest
```

## Tune the hyperparameters for XGBoost

```{r}
xgbParamSpace <-
    makeParamSet(makeNumericParam("eta", lower = 0, upper = 1),
                 makeNumericParam("gamma", lower = 0, upper = 10),
                 makeIntegerParam("max_depth", lower = 1, upper = 20),
                 makeNumericParam("min_child_weight", lower = 1, upper = 10),
                 makeNumericParam("subsample", lower = 0.5, upper = 1),
                 makeNumericParam("colsample_bytree", lower = 0.5, upper = 1),
                 makeIntegerParam("nrounds", lower = 50, upper = 50))

tunedXgb <- tuneParams(xgb,
                       task = infantMortalityTaskTrain,
                       resampling = kFold10,
                       par.set = xgbParamSpace,
                       control = randSearch)

tunedXgb
```

## Train random forest and XGBoost models

We are also going to check and see if the mean squared error (MSE) converges with the number of trees trained.

```{r}
# set hyperparameter for k-nearest neighbor
tunedKnnPars <- setHyperPars(knn, par.vals = tunedKnn$x)
trainedKnn <- train(tunedKnnPars, infantMortalityTaskTrain)

# set hyperparameters and train the random forest
tunedRandomForestPars <- setHyperPars(forest, par.vals = tunedRandomForest$x)
trainedRandomForest <- train(tunedRandomForestPars, infantMortalityTaskTrain)

# set hyperparameters and train xgboost
tunedXgbPars <- setHyperPars(xgb, par.vals = tunedXgb$x)
trainedXgb <- train(tunedXgbPars, infantMortalityTaskTrain)

# Check to see if our MSE converges for random forest
randomForestData <- trainedRandomForest$learner.model
plot(randomForestData)

# Check to see if our MSE converges for XGBoost
xgbData <- trainedXgb$learner.model
ggplot(xgbData$evaluation_log, aes(iter, train_rmse)) +
    geom_line() +
    geom_point() +
    theme_bw()
```

## See how well our models do predicting out of sample on the test set.

As a reminder, we will be using MSE (mean square error) to evaluate peformance.

$\frac{1}{n}\sum_{i=1}^n(Y_i - \hat{Y_i}^2)$

```{r}
predictKnn <-
    as_tibble(predict(trainedKnn,
                      newdata = select(testImputed, -year, -state))) %>%
    mutate(error = truth - response,
           error_sq = error ^ 2,
           sum_sq_error = sum(error_sq),
           mse = sum_sq_error / n())

predictRandomForest <-
    as_tibble(predict(trainedRandomForest,
                      newdata = select(testImputed, -year, -state))) %>%
    mutate(error = truth - response,
           error_sq = error ^ 2,
           sum_sq_error = sum(error_sq),
           mse = sum_sq_error / n())

predictXgb <-
    as_tibble(predict(trainedXgb,
                      newdata = select(testImputed, -year, -state))) %>%
    mutate(error = truth - response,
           error_sq = error ^ 2,
           sum_sq_error = sum(error_sq),
           mse = sum_sq_error / n())

cat("knn: ", unique(predictKnn$mse))
cat("random forest: ", unique(predictRandomForest$mse))
cat("xgb: ", unique(predictXgb$mse))
```

## Let's visualize the predictions and how well they line up with the actual values

```{r}
ggplot(predictKnn, aes(x = truth, y = response)) +
    geom_point() +
    geom_abline(intercept = 0, slope = 1) +
    theme_bw() +
    labs(title = "kNN predicted vs. truth")

ggplot(predictRandomForest, aes(x = truth, y = response)) +
    geom_point() +
    geom_abline(intercept = 0, slope = 1) +
    theme_bw() +
    labs(title = "Random Forest predicted vs. truth")

ggplot(predictXgb, aes(x = truth, y = response)) +
    geom_point() +
    geom_abline(intercept = 0, slope = 1) +
    theme_bw() +
    labs(title = "Xgb predicted vs. truth")
```

## See which features were most important in random forest vs. xgboost

```{r}
randomForestFeatures <-
    getFeatureImportance(trainedRandomForest)$res %>%
    mutate(model = "randomForest")

xgboostFeatures <-
    getFeatureImportance(trainedXgb)$res %>%
    mutate(model = "xgboost")

features <- bind_rows(randomForestFeatures, xgboostFeatures)

ggplot(features, aes(x = reorder(variable, importance), y = importance)) +
    geom_bar(stat = "identity") +
    facet_wrap(~ model, scales = "free_x") +
    coord_flip() +
    theme_bw()
```
